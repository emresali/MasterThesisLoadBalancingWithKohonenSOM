# Kohonen Self-Organizing Maps Configuration
# ==========================================
# Based on Teuvo Kohonen's original algorithm

# Server Setup
servers:
  # Different system sizes to test
  scenarios:
    small:
      count: 10
      description: "Small cluster"
    medium:
      count: 25
      description: "Medium data center"
    large:
      count: 50
      description: "Large data center"
    enterprise:
      count: 100
      description: "Enterprise-scale system"
  
  # Default for experiments
  default_scenario: 'medium'
  
  # For ExperimentRunner compatibility
  count: 25  # Default server count

# Kohonen Map (SOM) Specific Parameters
som_parameters:
  # Kohonen Map dimensions
  map_dimensions:
    small: 8    # 8x8 = 64 neurons
    medium: 10  # 10x10 = 100 neurons
    large: 15   # 15x15 = 225 neurons
    
  # Kohonen learning parameters
  learning:
    # Initial learning rate (α₀) - classically high
    initial_alpha: 0.9
    
    # Minimum learning rate (α_min)
    min_alpha: 0.01
    
    # Learning rate decay: α(t) = α₀ * exp(-t/λ)
    decay_function: 'exponential'
    decay_constant_lambda: 1000
  
  # Kohonen neighborhood function
  neighborhood:
    # Gaussian neighborhood (Kohonen standard)
    function: 'gaussian'  # h(r,t) = exp(-r²/2σ²(t))
    
    # Initial neighborhood radius (σ₀)
    initial_sigma: 3.0
    
    # Minimum radius (σ_min)
    min_sigma: 0.5
    
    # Radius decay: σ(t) = σ₀ * exp(-t/λ_σ)
    sigma_decay_constant: 500
  
  # Training
  training:
    # Initial training
    initial_iterations: 1000  # Coarse ordering
    
    # Online learning
    online_learning: true
    retrain_interval: 100  # Every N requests
    retrain_iterations: 50  # Fine-tuning

# Workload Patterns for Kohonen Evaluation
simulation:
  # Request patterns
  request_patterns:
    - name: "small"
      weight: 0.6
      cpu_intensity_range: [1, 4]    # Will be divided by 10
      memory_intensity_range: [1, 4]
    - name: "medium"
      weight: 0.3
      cpu_intensity_range: [3, 6]
      memory_intensity_range: [3, 6]
    - name: "large"
      weight: 0.1
      cpu_intensity_range: [6, 9]
      memory_intensity_range: [6, 9]
  
  # Workload scenarios
  workloads:
    # Pattern 1: Uniform load (baseline)
    uniform:
      description: "Uniformly distributed requests"
      request_rate: 50  # Requests/second
      cpu_demand: [0.1, 0.4]
      memory_demand: [0.1, 0.4]
      
    # Pattern 2: Hotspot scenario
    hotspot:
      description: "80% small, 20% large requests"
      request_rate: 50
      small_requests:
        probability: 0.8
        cpu_demand: [0.05, 0.2]
        memory_demand: [0.05, 0.2]
      large_requests:
        probability: 0.2
        cpu_demand: [0.6, 0.9]
        memory_demand: [0.6, 0.9]
    
    # Pattern 3: Time-varying load
    time_varying:
      description: "Time-of-day dependent load"
      phases:
        - name: "Night"
          duration_percent: 25
          request_rate: 20
          cpu_demand: [0.1, 0.3]
        - name: "Morning peak"
          duration_percent: 25
          request_rate: 100
          cpu_demand: [0.3, 0.7]
        - name: "Noon"
          duration_percent: 25
          request_rate: 60
          cpu_demand: [0.2, 0.5]
        - name: "Evening peak"
          duration_percent: 25
          request_rate: 120
          cpu_demand: [0.4, 0.8]

# Experiments
experiments:
  # Parameter grid for sweep
  som_parameter_grid:
    som_size: [6, 8, 10, 12]
    learning_rate: [0.1, 0.3, 0.5, 0.7]
    sigma: [1.0, 1.5, 2.0, 2.5, 3.0]
  
  # Request counts for different experiment phases
  tuning_requests: 200     # Quick evaluation during parameter tuning
  comparison_requests: 1000 # Full evaluation for comparisons
  
  # Scalability tests
  scalability:
    server_counts: [10, 25, 50, 75, 100]
    request_loads: [100, 500, 1000, 5000, 10000]
    measure: ['response_time', 'success_rate', 'load_distribution']
  
  # Adaptivity tests
  adaptivity:
    test_scenarios:
      - "Sudden load spike"
      - "Gradual increase"
      - "Server failure"
      - "Workload pattern change"

# Metrics for Kohonen Evaluation
metrics:
  # Kohonen-specific metrics
  som_metrics:
    - neuron_utilization      # How many neurons are active?
    - topology_preservation   # Topology preservation
    - quantization_error      # Average quantization error
    - learning_convergence    # Weight convergence
  
  # Load balancing metrics
  performance_metrics:
    - request_success_rate
    - server_load_variance    # Server load variance
    - response_time_percentiles  # P50, P95, P99
    - load_balance_index      # Jain's Fairness Index
  
  # System metrics
  system_metrics:
    - cpu_utilization_per_server
    - memory_utilization_per_server
    - request_queue_length
    - rejected_requests

# Visualization
visualization:
  # Kohonen Map visualizations
  som_plots:
    - u_matrix              # Unified Distance Matrix
    - hit_map               # Which neurons are how often active
    - weight_positions      # 2D projection of weights
    - learning_curves       # α(t) and σ(t) over time
  
  # Performance plots
  performance_plots:
    - server_load_heatmap
    - response_time_distribution
    - success_rate_over_time
    - load_variance_comparison
  
  # Comparison plots
  comparison_plots:
    - som_vs_roundrobin
    - som_vs_leastconnections
    - parameter_impact_matrix

# Output
output:
  # Results directory
  results_dir: "data/results"
  plots_dir: "data/plots"
  
  # Export formats
  export_formats:
    - csv
    - json
    - latex_table  # For academic papers
  
  # Plot settings
  plot_settings:
    dpi: 300
    format: 'png'  # Also supports 'pdf' for LaTeX
    font_size: 12
    style: 'scientific'